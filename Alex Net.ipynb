{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCiTyVTyn6qv"
   },
   "source": [
    "# TRAINING FACE MASK DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m67oyMVDn6qw"
   },
   "source": [
    "## IMPORTING NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nHj_QjPun6qw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.utils import img_to_array\n",
    "from keras.utils import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import keras\n",
    "from tensorflow.python.keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSuB893cpUxY"
   },
   "source": [
    "### Mounting Drive & Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EwzcMY1In6qx"
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "directory=\"C:/Users/smahamka/Desktop/Intro to dl/data\"\n",
    "categories=[\"with_mask\",\"without_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDXrsmyrn6qx",
    "outputId": "370d585d-b4ec-4575-9a77-ee89232d568f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smahamka\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for imagePath in categories:\n",
    "    path=os.path.join(directory,imagePath)\n",
    "    for img in os.listdir(path):\n",
    "        img_path=os.path.join(path,img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(imagePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X0WDJzOn6q3"
   },
   "source": [
    "### PERFORMING ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rXXF2VXEn6q3"
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvP__5BKn6q3"
   },
   "source": [
    "### PARTIONING THE DATA INTO TRAINING AND TESTING SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mImoK1Ain6q3"
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sFHM2FqCd4k",
    "outputId": "9d6a0e7e-93a9-450a-efcf-c592cdf6db3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 54, 54, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 26, 26, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12, 12, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,979,394\n",
      "Trainable params: 29,976,642\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smahamka\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=96, kernel_size=(11, 11), \n",
    "                        strides=(4, 4), activation=\"relu\", \n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(4096, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=  tf.optimizers.SGD(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "Ob6mkAoLc3lb",
    "outputId": "c8d03409-05c2-44b8-bc32-af3e412144ab"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualkeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7948\\3455325768.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayered_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualkeras'"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9SDzZopn6q5",
    "outputId": "bc26c54e-d9f2-4c5d-bc30-e499e2b28343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 415s 2s/step - loss: 0.6646 - accuracy: 0.7749 - val_loss: 0.5549 - val_accuracy: 0.8564\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 416s 2s/step - loss: 0.4530 - accuracy: 0.8486 - val_loss: 0.3081 - val_accuracy: 0.8769\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 412s 2s/step - loss: 0.3802 - accuracy: 0.8676 - val_loss: 0.2068 - val_accuracy: 0.9212\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 418s 2s/step - loss: 0.3201 - accuracy: 0.8899 - val_loss: 0.1747 - val_accuracy: 0.9418\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 407s 2s/step - loss: 0.2914 - accuracy: 0.8985 - val_loss: 0.1709 - val_accuracy: 0.9398\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 407s 2s/step - loss: 0.2595 - accuracy: 0.9106 - val_loss: 0.1370 - val_accuracy: 0.9510\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 399s 2s/step - loss: 0.2347 - accuracy: 0.9193 - val_loss: 0.1424 - val_accuracy: 0.9477\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 452s 2s/step - loss: 0.2170 - accuracy: 0.9266 - val_loss: 0.1166 - val_accuracy: 0.9603\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 407s 2s/step - loss: 0.1894 - accuracy: 0.9329 - val_loss: 0.1213 - val_accuracy: 0.9576\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 403s 2s/step - loss: 0.2017 - accuracy: 0.9314 - val_loss: 0.1265 - val_accuracy: 0.9550\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 419s 2s/step - loss: 0.1916 - accuracy: 0.9304 - val_loss: 0.1030 - val_accuracy: 0.9656\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 445s 2s/step - loss: 0.1790 - accuracy: 0.9384 - val_loss: 0.0925 - val_accuracy: 0.9729\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 460s 2s/step - loss: 0.1669 - accuracy: 0.9396 - val_loss: 0.0894 - val_accuracy: 0.9689\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 438s 2s/step - loss: 0.1656 - accuracy: 0.9414 - val_loss: 0.1239 - val_accuracy: 0.9603\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 460s 2s/step - loss: 0.1545 - accuracy: 0.9471 - val_loss: 0.0845 - val_accuracy: 0.9715\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 419s 2s/step - loss: 0.1354 - accuracy: 0.9539 - val_loss: 0.0979 - val_accuracy: 0.9629\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 450s 2s/step - loss: 0.1338 - accuracy: 0.9556 - val_loss: 0.0985 - val_accuracy: 0.9689\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 456s 2s/step - loss: 0.1342 - accuracy: 0.9561 - val_loss: 0.1379 - val_accuracy: 0.9484\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 403s 2s/step - loss: 0.1219 - accuracy: 0.9586 - val_loss: 0.0799 - val_accuracy: 0.9689\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 407s 2s/step - loss: 0.1186 - accuracy: 0.9594 - val_loss: 0.0838 - val_accuracy: 0.9715\n",
      "[INFO] evaluating network...\n",
      "48/48 [==============================] - 29s 596ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "# H = model.fit(\n",
    "#     aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     steps_per_epoch=len(trainX) // BS,\n",
    "#     validation_data=(testX, testY),\n",
    "#     validation_steps=len(testX) // BS,\n",
    "#     epochs=EPOCHS)\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    \n",
    "    epochs=20)\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YnJ9nipn6q6"
   },
   "source": [
    "### CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJRhnYFXn6q6",
    "outputId": "0047c11f-fcdc-4b4f-97c5-030ed036765f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(predIdxs)\n",
    "predIdxs = np.argmax(predIdxs)\n",
    "print(predIdxs)\n",
    "print(testY)\n",
    "\n",
    "# print(classification_report(testY, predIdxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 703s 4s/step - loss: 0.1211 - accuracy: 0.9611 - val_loss: 0.1175 - val_accuracy: 0.9610\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 682s 4s/step - loss: 0.1203 - accuracy: 0.9594 - val_loss: 0.0760 - val_accuracy: 0.9729\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 688s 4s/step - loss: 0.1060 - accuracy: 0.9622 - val_loss: 0.0805 - val_accuracy: 0.9649\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 687s 4s/step - loss: 0.1202 - accuracy: 0.9569 - val_loss: 0.0865 - val_accuracy: 0.9682\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 631s 3s/step - loss: 0.1162 - accuracy: 0.9599 - val_loss: 0.0745 - val_accuracy: 0.9682\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 530s 3s/step - loss: 0.0994 - accuracy: 0.9647 - val_loss: 0.0626 - val_accuracy: 0.9788\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 491s 3s/step - loss: 0.1007 - accuracy: 0.9641 - val_loss: 0.0708 - val_accuracy: 0.9729\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 511s 3s/step - loss: 0.0969 - accuracy: 0.9674 - val_loss: 0.0535 - val_accuracy: 0.9808\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 600s 3s/step - loss: 0.0921 - accuracy: 0.9687 - val_loss: 0.0623 - val_accuracy: 0.9749\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 626s 3s/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 0.0532 - val_accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 544s 3s/step - loss: 0.0955 - accuracy: 0.9666 - val_loss: 0.0643 - val_accuracy: 0.9762\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 498s 3s/step - loss: 0.0985 - accuracy: 0.9672 - val_loss: 0.0596 - val_accuracy: 0.9762\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 441s 2s/step - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.0869 - val_accuracy: 0.9722\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 442s 2s/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.0626 - val_accuracy: 0.9742\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 501s 3s/step - loss: 0.0794 - accuracy: 0.9739 - val_loss: 0.0656 - val_accuracy: 0.9768\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 576s 3s/step - loss: 0.0807 - accuracy: 0.9727 - val_loss: 0.0520 - val_accuracy: 0.9775\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 587s 3s/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.0505 - val_accuracy: 0.9801\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 534s 3s/step - loss: 0.0727 - accuracy: 0.9754 - val_loss: 0.0663 - val_accuracy: 0.9768\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 571s 3s/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 0.0509 - val_accuracy: 0.9788\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 574s 3s/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 0.0561 - val_accuracy: 0.9821\n",
      "[INFO] evaluating network...\n",
      "48/48 [==============================] - 35s 736ms/step\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    \n",
    "    epochs=20)\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
